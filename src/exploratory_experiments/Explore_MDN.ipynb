{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e852aa93",
   "metadata": {},
   "source": [
    "# Explore how to work with a Mixture Density Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from behavior_cloning.mdn import MDN, mdn_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify and load the experiment\n",
    "experiment = \"behavior_cloning\"\n",
    "run = \"mdn_00\" \n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271797c",
   "metadata": {},
   "source": [
    "### Generate synthetic training data\n",
    "The synthetic training data is a noisy sine wave, defined on the interval [-]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "beb8de33",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# --- Example Usage ---\n",
    "# 1. Generate some synthetic data (e.g., a noisy sine wave)\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "X = np.random.rand(num_samples, 1) * 10 - 5 # Input in range [-5, 5]\n",
    "# X = np.random.uniform(-5, 5, num_samples) \n",
    "# ^ this creates just a vector, not the right shape\n",
    "y_true = np.sin(X) * 2 + np.random.randn(num_samples, 1) * 0.5 # Noisy sine wave\n",
    "\n",
    "# Introduce some multi-modality for demonstration\n",
    "y_true[X[:, 0] > 2] += 2 # Shift part of the sine wave up\n",
    "y_true[X[:, 0] < -2] -= 2 # Shift part of the sine wave down\n",
    "\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8981cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "# 1. Generate some synthetic data (e.g., a noisy sine wave)\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "X = np.random.rand(num_samples, 1) * 10 - 5 # Input in range [-5, 5]\n",
    "# X = np.random.uniform(-5, 5, num_samples) \n",
    "# ^ this creates just a vector, not the right shape\n",
    "y_true = np.sin(X) * 2 + np.random.randn(num_samples, 1) * 0.5 # Noisy sine wave\n",
    "\n",
    "# Introduce some multi-modality for demonstration\n",
    "# y_true[X[:, 0] > 2] += 2 # Shift part of the sine wave up\n",
    "# y_true[X[:, 0] < -2] -= 2 # Shift part of the sine wave down\n",
    "y_true[0:num_samples//3] = -2.0 * y_true[0:num_samples//3] # Shift part of the sine wave up\n",
    "\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "x = X_tensor.numpy()\n",
    "y = y_tensor.numpy()\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1af4d",
   "metadata": {},
   "source": [
    "### Training the MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "num_gaussians = 5 # Number of Gaussian components\n",
    "\n",
    "model = MDN(exp)\n",
    "model_path = pathlib.Path(exp.data_dir(), \"mdn.pth\")\n",
    "if model_path.exists():\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    # model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    num_epochs = 200 # was 2000, buty it was not improving after 100\n",
    "    batch_size = 64\n",
    "\n",
    "    # X_tensor = X_tensor.to(device)\n",
    "    # y_tensor = y_tensor.to(device)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Mini-batch training\n",
    "        permutation = torch.randperm(num_samples)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_X, batch_y = X_tensor[indices], y_tensor[indices]\n",
    "            # batch_X = batch_X.to(device)\n",
    "            # batch_y = batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            mu, sigma, pi = model(batch_X)\n",
    "            loss = mdn_loss(batch_y, mu, sigma, pi)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98faf6f",
   "metadata": {},
   "source": [
    "### Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de457f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Make predictions and visualize\n",
    "# Create a range of input values for prediction\n",
    "X_test = torch.linspace(-5, 5, 500).unsqueeze(1)\n",
    "with torch.no_grad():\n",
    "    mu_pred, sigma_pred, pi_pred = model(X_test)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, y_true, s=10, alpha=0.3, label='True Data')\n",
    "\n",
    "# Plot the means\n",
    "for i in range(num_gaussians):\n",
    "    plt.plot(X_test.numpy(), mu_pred[:, 0, i].numpy(), '--', alpha=0.7,\n",
    "                label=f'Mean {i+1}')\n",
    "\n",
    "# Plot the predicted distribution's mean (weighted average of component means)\n",
    "# This is often not very informative for multimodal distributions, but good for understanding\n",
    "weighted_mean = torch.sum(pi_pred * mu_pred, dim=-1)\n",
    "plt.plot(X_test.numpy(), weighted_mean[:, 0].numpy(), 'k-', linewidth=2, label='Weighted Mean')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the predictive distribution (e.g., by sampling or showing density contours)\n",
    "# A common way is to draw samples from the predicted mixture model\n",
    "num_samples_from_mdn = 2000\n",
    "\n",
    "# FIXME: this is using this model which only samples along one dimension...\n",
    "y_samples = model.sample_0(num_samples_from_mdn, mu_pred, sigma_pred, pi_pred)\n",
    "print(y_samples.shape)\n",
    "\n",
    "# retval = torch.cat(y_samples).numpy()            \n",
    "# flatten out all the examples \n",
    "\n",
    "\n",
    "X_test_repeated = X_test.repeat_interleave(num_samples_from_mdn, dim=0).numpy()\n",
    "plt.hist2d(X_test_repeated.flatten(), y_samples.flatten(), bins=(50, 50), cmap='Blues', alpha=0.6, density=True)\n",
    "plt.colorbar(label='Density')\n",
    "plt.title('Mixed Density Network Prediction')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can also visualize individual Gaussian components for a specific input X\n",
    "# For example, let's pick a specific X value (e.g., X = 0)\n",
    "x_example = torch.tensor([[0.5]])\n",
    "with torch.no_grad():\n",
    "    mu_ex, sigma_ex, pi_ex = model(x_example)\n",
    "\n",
    "print(f\"\\nFor X = {x_example.item()}:\")\n",
    "for i in range(num_gaussians):\n",
    "    print(f\"  Gaussian {i+1}:\")\n",
    "    print(f\"    Mean (mu): {mu_ex[0, 0, i].item():.4f}\")\n",
    "    print(f\"    Std Dev (sigma): {sigma_ex[0, 0, i].item():.4f}\")\n",
    "    print(f\"    Mixing Coeff (pi): {pi_ex[0, 0, i].item():.4f}\")\n",
    "\n",
    "mu_ex_np = mu_ex.numpy()\n",
    "sigma_ex_np = sigma_ex.numpy()\n",
    "pi_ex_np = pi_ex.numpy()\n",
    "\n",
    "# Plot the individual Gaussians for the example\n",
    "plt.figure(figsize=(8, 5))\n",
    "y_vals = np.linspace(-5, 5, 500)\n",
    "for i in range(num_gaussians):\n",
    "    pdf = (1 / (sigma_ex_np[0, 0, i] * np.sqrt(2 * np.pi))) * \\\n",
    "          np.exp(-0.5 * ((y_vals - mu_ex_np[0, 0, i]) / sigma_ex_np[0, 0, i])**2)\n",
    "    plt.plot(y_vals, pdf * pi_ex_np[0, 0, i], label=f'Component {i+1} (weighted)')\n",
    "\n",
    "plt.title(f'Individual Gaussian Components for X = {x_example.item()}')\n",
    "plt.xlabel('Y')\n",
    "plt.ylabel('Probability Density (weighted)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43eda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
