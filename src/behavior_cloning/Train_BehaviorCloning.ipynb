{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train behavior cloning\n",
    "\n",
    "Train a behavior cloning based robot controller. \n",
    "* Code for loading and pre-processing the training data, typically from a set of demonstrations as specified in an exp/run\n",
    "* Train the behavior cloning controller. \n",
    "* The trained controllers should be saved into the exp/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from bc_trainingdata import create_trainingdata_bc\n",
    "from bc_factory import create_bc_model\n",
    "# FIXME: factor this out\n",
    "from bc_LSTM_MDN import bc_LSTM_MDN, mdn_loss\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\behavior_cloning\\bc_lstm_resid_00_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: behavior_cloning/bc_lstm_resid_00 successfully loaded\n",
      "Experiment:\n",
      "    control_size: 6\n",
      "    controller: bc_LSTM_Residual\n",
      "    controller_file: controller.pth\n",
      "    data_dir: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\behavior_cloning\\bc_lstm_resid_00\n",
      "    epochs: 10\n",
      "    exp_run_sys_indep_file: C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\behavior_cloning\\bc_lstm_resid_00.yaml\n",
      "    experiment_name: behavior_cloning\n",
      "    hidden_size: 32\n",
      "    loss: MSELoss\n",
      "    name: bc_lstm_resid_00\n",
      "    optimizer: Adam\n",
      "    optimizer_lr: 0.001\n",
      "    run_name: bc_lstm_resid_00\n",
      "    sequence_lenght: 10\n",
      "    sequence_length: 10\n",
      "    sp_experiment: sensorprocessing_conv_vae\n",
      "    sp_run: sp_vae_256\n",
      "    subrun_name: null\n",
      "    test_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_23_19'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_24_52'\n",
      "      - dev2\n",
      "    training_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_15_53'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_16_57'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_19_12'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\sensorprocessing_conv_vae\\sp_vae_256_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_256 successfully loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\robot_al5d\\position_controller_00_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: robot_al5d/position_controller_00 successfully loaded\n"
     ]
    }
   ],
   "source": [
    "experiment = \"behavior_cloning\"\n",
    "# run = \"bc_mlp_00\"\n",
    "# run = \"bc_lstm_00\"\n",
    "run = \"bc_lstm_resid_00\"\n",
    "# run = \"bc_lstm_mdn_00\"\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "\n",
    "#exp = Config().get_experiment(experiment, run, creation_style=\"discard-old\")\n",
    "pprint.pprint(exp)\n",
    "spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
    "\n",
    "robot_exp = Config().get_experiment(\"robot_al5d\", \"position_controller_00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an RNN model\n",
    "Functions for training an RNN type model. These models assume that the input is a sequence $[z_{t-k},...z_{t}]$ while the output is the next action $a_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bc_rnn(model, criterion, data, device):\n",
    "    \"\"\"Calculates the average validation error for the behavior cloning model using an RNN with the specific criterion function. Uses the z_validation an a_validation fields in \"data\". The inputs and the targets a list of individual input and target. \n",
    "    CHECK: I think that the target is supposed to be the last output of the RNN when the whole input string had been passed through it. \n",
    "    The model is reset before each of the strings (i.e. state is not transferred)\n",
    "    model: an LSTM or similar model that can consume a sequence of inputs\n",
    "    criterion: any function that calculates the distance between the targets\n",
    "    \"\"\"\n",
    "    num_sequences = data[\"z_validation\"].shape[0]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i in range(num_sequences):\n",
    "            # Forward pass\n",
    "            input_seq = data[\"z_validation\"][i].to(device)\n",
    "            target = data[\"a_validation\"][i].to(device)\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "            if not isinstance(model, bc_LSTM_MDN):\n",
    "                outputs = model(input_seq)\n",
    "                loss = criterion(outputs, target)\n",
    "            else: # for MDN, the output is sampling (in the future) but still using the criterion even if we didn't use it for training\n",
    "                outputs = model.forward_and_sample(input_seq)\n",
    "                # unclear why this is necessary\n",
    "                # outputs = outputs.to(device)\n",
    "                loss = criterion(outputs, target)\n",
    "                # outputs = model.forward(input_seq)\n",
    "                #loss = mdn_loss(target, *outputs)\n",
    "            # Accumulate loss\n",
    "            val_loss += loss.item()\n",
    "    avg_loss = val_loss / num_sequences\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bc_rnn(model, optimizer, criterion, data, num_epochs, writer = None):\n",
    "    \"\"\"Train a behavior cloning model using a sequence model (eg. an RNN)\n",
    "    Uses a writer for TensorBoard _and_ tqdm\n",
    "    \"\"\"\n",
    "    exp.start_timer(\"train\")\n",
    "    num_sequences = data[\"z_train\"].shape[0]\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        # Loop over each sequence in the batch\n",
    "        training_loss = 0\n",
    "        for i in range(num_sequences):\n",
    "            # Prepare input and target\n",
    "            input_seq = data[\"z_train\"][i].to(device)\n",
    "            target = data[\"a_train\"][i].to(device)\n",
    "\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input_seq)\n",
    "            # Check for MDN, that is different\n",
    "            if not isinstance(model, bc_LSTM_MDN):\n",
    "                loss = criterion(output, target)\n",
    "            else: \n",
    "                loss = mdn_loss(target, *output)\n",
    "            training_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_training_loss = training_loss / num_sequences\n",
    "        avg_validation_loss = validate_bc_rnn(model, criterion, data, device)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"TrainingLoss\", avg_training_loss, epoch)\n",
    "            writer.add_scalar(\"ValidationLoss\", avg_validation_loss, epoch)\n",
    "            writer.flush()\n",
    "        if (epoch+1) % 2 == 0: # was 0\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_training_loss:.4f} Validation Loss: {avg_validation_loss:.4f} ')\n",
    "    print(\"Training complete.\")\n",
    "    exp.end_timer(\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n",
    "Creates and trains a behavior cloning model specified by the exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc_LSTM_Residual(\n",
      "  (lstm_1): LSTM(256, 32, batch_first=True)\n",
      "  (lstm_2): LSTM(32, 32, batch_first=True)\n",
      "  (lstm_3): LSTM(32, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, criterion, optimizer = create_bc_model(exp, spexp, device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Timer*** data_preparation started\n",
      "***Timer*** data_preparation finished in 0.194313 seconds\n",
      "***Timer*** train started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:34<02:19, 17.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 1.8246 Validation Loss: 1.8786 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:04<01:33, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 1.1315 Validation Loss: 1.2255 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:36<01:03, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.6980 Validation Loss: 0.8464 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:03<00:29, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.4336 Validation Loss: 0.6342 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:30<00:00, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.4088 Validation Loss: 0.4752 \n",
      "Training complete.\n",
      "***Timer*** train finished in 150.126066 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = create_trainingdata_bc(exp, spexp, robot_exp, device=\"cpu\")\n",
    "# Training Loop\n",
    "num_epochs = exp[\"epochs\"]\n",
    "\n",
    "# Create a SummaryWriter instance\n",
    "# where does the logdir go???\n",
    "writer = SummaryWriter(logdir=\"/home/lboloni/runs/example\")\n",
    "train_bc_rnn(\n",
    "        model, optimizer, criterion, data=data,\n",
    "        num_epochs=num_epochs, writer=writer)\n",
    "writer.close()\n",
    "controller_path = pathlib.Path(exp.data_dir(), exp[\"controller_file\"])\n",
    "torch.save(model.state_dict(), controller_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
