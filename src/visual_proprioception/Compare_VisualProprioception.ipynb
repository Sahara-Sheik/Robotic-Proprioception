{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models for visual proprioception\n",
    "\n",
    "Compares regression models for visual proprioception, by running them on specific test data, and creating comparison graphs that put all of them onto the graphs. \n",
    "\n",
    "Each configuration is specified by a run of type visual_proprioception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "# fixing the fact that it defaults to Type 3 fonts\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "#import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#from sensorprocessing import sp_conv_vae, sp_propriotuned_cnn, sp_vit\n",
    "\n",
    "from visual_proprioception.visproprio_helper import load_demonstrations_as_proprioception_training, load_multiview_demonstrations_as_proprioception_training\n",
    "from visual_proprioception.visproprio_models import VisProprio_SimpleMLPRegression\n",
    "import sensorprocessing.sp_factory as sp_factory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Code for deterministic run, from Robi Konievic\n",
    "#\n",
    "superpower=777\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(superpower)\n",
    "import random\n",
    "random.seed(superpower)\n",
    "import numpy as np\n",
    "np.random.seed(superpower)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed_all(superpower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# If it is set to discard-old, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "experiment = \"visual_proprioception\"\n",
    "# run = \"vp_comp_flow_all\"\n",
    "run = \"vit_base\"\n",
    "\n",
    "# If not None, set the epochs to something different than the exp\n",
    "epochs = None\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "#external_path = r\"C:\\Users\\lotzi\\Work\\_DataExternal\\VisualProprioception_flow_00\\exprun\"\n",
    "# external_path = r\"C:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\cvpr_simulation_000\\exprun\"\n",
    "\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "#data_path = r\"C:\\Users\\lotzi\\Work\\_DataExternal\\VisualProprioception_flow_00\\result\"\n",
    "# data_path = r\"C:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\cvpr_simulation_000\\result\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_exprun_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_aruco\")\n",
    "    Config().copy_experiment(\"sensorprocessing_conv_vae\")\n",
    "    Config().copy_experiment(\"sensorprocessing_propriotuned_Vit\")\n",
    "    Config().copy_experiment(\"sensorprocessing_propriotuned_cnn\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_results_path(data_path)\n",
    "\n",
    "exp = Config().get_experiment(experiment, run)\n",
    "# runs = exp[\"tocompare\"]\n",
    "# run = \"vp_ptun_vgg19_128\"\n",
    "runs = [\"vit_base\"]\n",
    "# runs = [\"vp_convvae_128\", \"vp_convvae_256\", \"vp_ptun_vgg19_128\", \"vp_ptun_vgg19_256\", \"vp_ptun_resnet50_128\", \"vp_ptun_resnet50_256\", \"vp_aruco_128\"]\n",
    "\n",
    "\n",
    "exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
    "subexps = [] # the sub experiments that we are comparing\n",
    "sps = [ ]\n",
    "spexps = [ ]\n",
    "models = [ ]\n",
    "# FIXME: it is not a good idea to hardwire this, later we should refer\n",
    "# from the comparison exprun\n",
    "exp_robot = Config().get_experiment(\"robot_al5d\", \"position_controller_00\")\n",
    "firstexp = None # the first experiment, this is where we get the data from\n",
    "for subrun in runs:\n",
    "    subexp = Config().get_experiment(experiment, subrun)\n",
    "    if firstexp is None:\n",
    "        firstexp = subexp\n",
    "    subexps.append(subexp)\n",
    "    spexp = Config().get_experiment(subexp[\"sp_experiment\"], subexp[\"sp_run\"])\n",
    "    spexps.append(spexp)\n",
    "    sp = sp_factory.create_sp(spexp, device)\n",
    "    sps.append(sp)\n",
    "    model = VisProprio_SimpleMLPRegression(subexp)\n",
    "    modelfile = pathlib.Path(subexp[\"data_dir\"],\n",
    "                            subexp[\"proprioception_mlp_model_file\"])\n",
    "    model.load_state_dict(torch.load(modelfile))\n",
    "    model.to(device)\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data for the lead experiment\n",
    "# task = leadexp[\"proprioception_testing_task\"]\n",
    "proprioception_input_file = pathlib.Path(\n",
    "    firstexp.data_dir(), firstexp[\"proprioception_test_input_file\"])\n",
    "proprioception_target_file = pathlib.Path(\n",
    "    firstexp.data_dir(), firstexp[\"proprioception_test_target_file\"])\n",
    "\n",
    "# Check if lead experiment is multi-view\n",
    "is_lead_multiview = exp.get(\"sensor_processing\", \"\") == \"Vit_multiview\" or firstexp.get(\"num_views\", 1) > 1\n",
    "\n",
    "if is_lead_multiview:\n",
    "    # Use multi-view loading function for the lead experiment\n",
    "    tr = load_multiview_demonstrations_as_proprioception_training(\n",
    "        task,\n",
    "        proprioception_input_file,\n",
    "        proprioception_target_file,\n",
    "        num_views=firstexp.get(\"num_views\", 2)\n",
    "    )\n",
    "else:\n",
    "    # Use original single-view loading function\n",
    "    # These are actually just using the last ones\n",
    "    tr = load_demonstrations_as_proprioception_training(\n",
    "        sps[0], firstexp, spexps[0], exp_robot, \"validation_data\", proprioception_input_file, proprioception_target_file, device=device\n",
    "    )\n",
    "\n",
    "\n",
    "# The targets should be the same regardless of single or multi-view\n",
    "targets = tr[\"targets\"]\n",
    "print(f\"There are {targets.shape[0]} target data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all the components. The thing with it though is that this will get the test data from the components, not from the lead exp.\n",
    "\n",
    "FIXME: maybe I could just write a function that runs a particular proprioceptor on a whole task and returns the y, and then just call that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_from = 0\n",
    "no_to = targets.shape[0]-1\n",
    "\n",
    "ypreds = []\n",
    "\n",
    "for subexp, sp, spexp, model in zip(subexps, sps, spexps, models):\n",
    "    # Make sure both sp and model are on the same device\n",
    "    model = model.to(device)\n",
    "    proprioception_input_file = pathlib.Path(\n",
    "        subexp.data_dir(), subexp[\"proprioception_test_input_file\"])\n",
    "    proprioception_target_file = pathlib.Path(\n",
    "        subexp.data_dir(), subexp[\"proprioception_test_target_file\"])\n",
    "\n",
    "    # Check if this is a multi-view model\n",
    "    is_multiview = subexp.get(\"sensor_processing\", \"\") == \"Vit_multiview\" or subexp.get(\"num_views\", 1) > 1\n",
    "\n",
    "    if is_multiview:\n",
    "        # Use the multi-view data loading function\n",
    "        tr = load_multiview_demonstrations_as_proprioception_training(\n",
    "            task,\n",
    "            proprioception_input_file,\n",
    "            proprioception_target_file,\n",
    "            num_views=subexp.get(\"num_views\", 2)\n",
    "        )\n",
    "\n",
    "        # Process each data point\n",
    "        ypred = []\n",
    "        y = []\n",
    "        t = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(no_from, no_to):\n",
    "                # Get the latent representation from sp (which handles the multi-view encoding)\n",
    "                views = [view[i].unsqueeze(0).to(device) for view in tr[\"view_inputs\"]]\n",
    "                latent = sp.process(views)\n",
    "\n",
    "                # Important: Make sure the latent tensor is on the same device as the model\n",
    "                latent_tensor = torch.from_numpy(latent).unsqueeze(0).to(device)\n",
    "                # Pass latent to regression model\n",
    "                predictions = model(latent_tensor)\n",
    "                # Append the data\n",
    "                t.append(i)\n",
    "                y.append(targets[i].numpy())\n",
    "                ypred.append(predictions[0].cpu().numpy())\n",
    "    else:\n",
    "        # Original single-view approach\n",
    "        tr = load_demonstrations_as_proprioception_training(\n",
    "            sp, subexp, spexp, exp_robot, \"validation_data\", proprioception_input_file, proprioception_target_file, device=device\n",
    "        )\n",
    "        inputs = tr[\"inputs\"]\n",
    "        ypred = []\n",
    "        y = []\n",
    "        t = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(no_from, no_to):\n",
    "                # Move input to the correct device\n",
    "                x = inputs[i].to(device)\n",
    "                predictions = model(torch.unsqueeze(x, dim=0))\n",
    "\n",
    "                # Move predictions back to CPU for numpy conversion\n",
    "                # Append the data\n",
    "                t.append(i)\n",
    "                y.append(targets[i].numpy())\n",
    "                ypred.append(predictions[0].cpu().numpy())\n",
    "\n",
    "    ypred = np.array(ypred)\n",
    "    ypreds.append(ypred)\n",
    "    y = np.array(y)\n",
    "    t = np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time compare plot - double column\n",
    "At this point, we should have the ypreds, the y and the t and we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(8, 6))\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//3, i%3]\n",
    "    # ax.set_ylim(0, 1.4)\n",
    "    ax.plot(t, y[:,i], label=\"ground truth\")\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        # fixme, fix the label to the name in the exp\n",
    "        ax.plot(t, ypred[:,i], label=subexp[\"name\"])\n",
    "    if i==0:\n",
    "        fig.legend(bbox_to_anchor=(1.25, 1))\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"comparison.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time compare plot, single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(7, 5.3))\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//3, i%3]\n",
    "    # ax.set_ylim(0, 2.0)\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        # fixme, fix the label to the name in the exp\n",
    "        ax.plot(t, ypred[:,i], label=subexp[\"name\"], linewidth=1)\n",
    "    ax.plot(t, y[:,i], label=\"ground truth\", linewidth=2, color=\"black\")\n",
    "    if i==2:\n",
    "        ax.legend()\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"comparison.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time compare plot, vertical with legend bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(3,2, figsize=(5.3, 7))\n",
    "fig, axs = plt.subplots(3,2, figsize=(4.6, 6))\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//2, i%2]\n",
    "    #ax.set_ylim(0, 2.0)\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        # fixme, fix the label to the name in the exp\n",
    "        ax.plot(t, ypred[:,i], label=subexp[\"name\"], linewidth=1)\n",
    "    ax.plot(t, y[:,i], label=\"ground truth\", linewidth=2, color=\"black\")\n",
    "    if i==4:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, ncol=len(subexps)+1,\n",
    "            bbox_to_anchor=(0.5, 0), loc=\"upper center\")\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"comparison23.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"comparison23.jpg\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the average accuracy\n",
    "Create a graph that is comparing the average accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(4, 3))\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//3, i%3]\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    # ax.plot(t, y[:,i], label=\"y\")\n",
    "    bars = []\n",
    "    names = []\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        ## FIXME: some kind of different plot\n",
    "        # error = avg(y[:,i], ypred[:,i])\n",
    "        error = math.sqrt(np.mean((y[:,i]- ypred[:,i]) ** 2))\n",
    "        br = ax.bar(subexp[\"name\"], error)\n",
    "        bars.append(br)\n",
    "        names.append(subexp[\"name\"])\n",
    "    # Remove x-axis labels if desired\n",
    "    ax.set_xticks([])\n",
    "    if i==0:\n",
    "        fig.legend(bars, names, bbox_to_anchor=(1.50, 0.9), ncol=1)\n",
    "    fig.tight_layout()\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison.jpg\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2, figsize=(4.6, 6))\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//2, i%2]\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    # ax.plot(t, y[:,i], label=\"y\")\n",
    "    bars = []\n",
    "    names = []\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        ## FIXME: some kind of different plot\n",
    "        # error = avg(y[:,i], ypred[:,i])\n",
    "        error = math.sqrt(np.mean((y[:,i]- ypred[:,i]) ** 2))\n",
    "        br = ax.bar(subexp[\"name\"], error, label=subexp[\"name\"])\n",
    "        bars.append(br)\n",
    "        names.append(subexp[\"name\"])\n",
    "    # Remove x-axis labels if desired\n",
    "    ax.set_xticks([])\n",
    "    if i==4:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        #ncolumn = len(exps)\n",
    "        ncolumn = 2\n",
    "        fig.legend(handles, labels, ncol=ncolumn,\n",
    "            bbox_to_anchor=(0.5, 0), loc=\"upper center\")\n",
    "    # fig.tight_layout()\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison23.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison23.jpg\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate csv file for further processing\n",
    "\n",
    "Code by Robert-Anton Konievic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(4, 3))\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    ax = axs[i//3, i%3]\n",
    "    # ax.set_ylim(0, 0.4)\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    # ax.plot(t, y[:,i], label=\"y\")\n",
    "    bars = []\n",
    "    names = []\n",
    "    with open(pathlib.Path(exp[\"data_dir\"], \"msecomparison_values.txt\"),'a') as mse_values_file:\n",
    "        mse_values_file.write(titles[i] + \": \" + '\\n')\n",
    "    for ypred, subexp in zip(ypreds,subexps):\n",
    "        ## FIXME: some kind of different plot\n",
    "        # error = avg(y[:,i], ypred[:,i])\n",
    "        error = math.sqrt(np.mean((y[:,i]- ypred[:,i]) ** 2))\n",
    "        br = ax.bar(subexp[\"name\"], error)\n",
    "        bars.append(br)\n",
    "        names.append(subexp[\"name\"])\n",
    "        with open(pathlib.Path(exp[\"data_dir\"],\n",
    "            \"msecomparison_values.txt\"),'a') as mse_values_file:\n",
    "            mse_values_file.write(subexp[\"name\"] + \": \" + str(error) + '\\n')\n",
    "    # csv_path = pathlib.Path(exp[\"data_dir\"], \"all_msecomparison_values.csv\")\n",
    "    csv_path = pathlib.Path(exp[\"data_dir\"], \"all_msecomparison_values.csv\")\n",
    "\n",
    "\n",
    "# If youâ€™re running this in a loop for multiple titles, open once per run\n",
    "# Use 'a' to append to the existing file, or 'w' to overwrite.\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write header row only if file is new/empty\n",
    "        if csv_path.stat().st_size == 0:\n",
    "            writer.writerow([\"Title\"] + [subexp[\"name\"] for subexp in subexps])\n",
    "         # Compute all errors for the current title\n",
    "        errors = []\n",
    "        for ypred, subexp in zip(ypreds, subexps):\n",
    "            error = math.sqrt(np.mean((y[:, i] - ypred[:, i]) ** 2))\n",
    "            errors.append(error)\n",
    "         # Write one row per title (e.g. per experiment)\n",
    "        writer.writerow([titles[i]] + errors)\n",
    "\n",
    "     # Remove x-axis labels if desired\n",
    "    ax.set_xticks([])\n",
    "    if i==0:\n",
    "        fig.legend(bars, names, bbox_to_anchor=(1.50, 0.9), ncol=1)\n",
    "    fig.tight_layout()\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "fig.tight_layout()\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison-robi.pdf\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"msecomparison-robi.jpg\")\n",
    "plt.savefig(graphfilename, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
