{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8934c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:49.306076Z",
     "iopub.status.busy": "2025-11-18T10:06:49.305934Z",
     "iopub.status.idle": "2025-11-18T10:06:49.311060Z",
     "shell.execute_reply": "2025-11-18T10:06:49.310190Z"
    },
    "papermill": {
     "duration": 0.009896,
     "end_time": "2025-11-18T10:06:49.311545",
     "exception": false,
     "start_time": "2025-11-18T10:06:49.301649",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "experiment = \"sensorprocessing_propriotuned_cnn\"\n",
    "run = \"sp_resnet50_256_0001\"\n",
    "external_path = \"~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun\"\n",
    "data_path = \"~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d3d58",
   "metadata": {
    "papermill": {
     "duration": 0.003103,
     "end_time": "2025-11-18T10:06:49.320361",
     "exception": false,
     "start_time": "2025-11-18T10:06:49.317258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train a proprioception-tuned CNN\n",
    "\n",
    "We create a sensor processing model using CNN-based visual encoding finetuned with proprioception.\n",
    "\n",
    "We create an encoding for the robot starting from a pretrained CNN model. As the feature vector of this is still large (eg 512 * 7 * 7), we reduce this to the encoding with an MLP. \n",
    "\n",
    "We finetune the encoding with information from proprioception.  \n",
    "\n",
    "The sensor processing object associated with the network trained like this is in sensorprocessing/sp_propriotuned_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a260de03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:49.327331Z",
     "iopub.status.busy": "2025-11-18T10:06:49.327190Z",
     "iopub.status.idle": "2025-11-18T10:06:51.850422Z",
     "shell.execute_reply": "2025-11-18T10:06:51.849431Z"
    },
    "papermill": {
     "duration": 2.527687,
     "end_time": "2025-11-18T10:06:51.850947",
     "exception": false,
     "start_time": "2025-11-18T10:06:49.323260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config, Experiment\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "import sensorprocessing.sp_helper as sp_helper\n",
    "from sensorprocessing.sp_propriotuned_cnn import VGG19ProprioTunedRegression, ResNetProprioTunedRegression\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8910b0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.861551Z",
     "iopub.status.busy": "2025-11-18T10:06:51.861288Z",
     "iopub.status.idle": "2025-11-18T10:06:51.869532Z",
     "shell.execute_reply": "2025-11-18T10:06:51.868679Z"
    },
    "papermill": {
     "duration": 0.0126,
     "end_time": "2025-11-18T10:06:51.870004",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.857404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Code for deterministic run, from Robi Konievic\n",
    "#\n",
    "superpower=777\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(superpower)\n",
    "import random\n",
    "random.seed(superpower)\n",
    "import numpy as np\n",
    "np.random.seed(superpower)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.manual_seed_all(superpower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8afff1",
   "metadata": {
    "papermill": {
     "duration": 0.003102,
     "end_time": "2025-11-18T10:06:51.876185",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.873083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Exp-run initialization\n",
    "Create the exp/run-s that describe the parameters of the training. \n",
    "Some of the code here is structured in such a way as to make the notebook automatizable with papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf6e8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.883273Z",
     "iopub.status.busy": "2025-11-18T10:06:51.883122Z",
     "iopub.status.idle": "2025-11-18T10:06:51.886376Z",
     "shell.execute_reply": "2025-11-18T10:06:51.885675Z"
    },
    "papermill": {
     "duration": 0.007607,
     "end_time": "2025-11-18T10:06:51.886842",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.879235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *** Initialize the variables with default values\n",
    "# *** This cell should be tagged as parameters\n",
    "# *** If papermill is used, some of the values will be overwritten\n",
    "\n",
    "# If it is set to discard-old, the exprun will be recreated from scratch\n",
    "creation_style = \"exist-ok\"\n",
    "\n",
    "experiment = \"sensorprocessing_propriotuned_cnn\"\n",
    "# run = \"vgg19_128\"\n",
    "# run = \"resnet50_128\"\n",
    "run = \"vgg19_256\"\n",
    "# run = \"resnet50_256\"\n",
    "# run = \"boo\"\n",
    "# If not None, set the epochs to something different than the exp\n",
    "epochs = None\n",
    "\n",
    "# If not None, set an external experiment path\n",
    "external_path = None\n",
    "# If not None, set an output path\n",
    "data_path = None\n",
    "\n",
    "# Dr. Boloni's path\n",
    "#external_path = pathlib.Path(Config()[\"experiment_external\"])\n",
    "# Sahara's path\n",
    "# external_path = pathlib.Path(\"/home/sa641631/SaharaBerryPickerData/experiment_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09b9802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.893708Z",
     "iopub.status.busy": "2025-11-18T10:06:51.893570Z",
     "iopub.status.idle": "2025-11-18T10:06:51.909649Z",
     "shell.execute_reply": "2025-11-18T10:06:51.908830Z"
    },
    "papermill": {
     "duration": 0.020103,
     "end_time": "2025-11-18T10:06:51.910111",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.890008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\t/home/sa641631/.config/BerryPicker/mainsettings.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading machine-specific config file:\n",
      "\t~/WORK/BerryPicker/cfg/settings.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: sensorprocessing_propriotuned_cnn/vgg19_256 successfully loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Configuration for exp/run: robot_al5d/position_controller_00 successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# create the necessary exp/run objects\n",
    "\n",
    "if external_path:\n",
    "    external_path = pathlib.Path(external_path)\n",
    "    assert external_path.exists()\n",
    "    Config().set_exprun_path(external_path)\n",
    "    Config().copy_experiment(\"sensorprocessing_propriotuned_cnn\")\n",
    "    Config().copy_experiment(\"robot_al5d\")\n",
    "    Config().copy_experiment(\"demonstration\")\n",
    "if data_path:\n",
    "    data_path = pathlib.Path(data_path)\n",
    "    assert data_path.exists()\n",
    "    Config().set_results_path(data_path)\n",
    "\n",
    "# This is an example of how to run an exprun variant\n",
    "# Config().create_exprun_variant(\"sensorprocessing_propriotuned_cnn\",\"resnet50_128\", {\"epochs\": 17}, new_run_name=\"boo\")\n",
    "\n",
    "# The experiment/run we are going to run: the specified model will be created\n",
    "exp = Config().get_experiment(experiment, run, creation_style=creation_style)\n",
    "exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec6eab",
   "metadata": {
    "papermill": {
     "duration": 0.00316,
     "end_time": "2025-11-18T10:06:51.916606",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.913446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create regression training data (image to proprioception)\n",
    "The training data (X, Y) is all the pictures from a demonstration with the corresponding proprioception data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56cfe772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.924610Z",
     "iopub.status.busy": "2025-11-18T10:06:51.924470Z",
     "iopub.status.idle": "2025-11-18T10:06:51.930876Z",
     "shell.execute_reply": "2025-11-18T10:06:51.930164Z"
    },
    "papermill": {
     "duration": 0.011752,
     "end_time": "2025-11-18T10:06:51.931524",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.919772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images_as_proprioception_training(exp: Experiment, exp_robot: Experiment):\n",
    "    \"\"\"Loads the training images specified in the exp/run. Processes them as two tensors as input and target data for proprioception training.\n",
    "    Caches the processed results into the input and target file specified in the exp/run.\n",
    "\n",
    "    Remove those files to recalculate\n",
    "    \"\"\"\n",
    "    retval = {}\n",
    "    proprioception_input_path = pathlib.Path(exp.data_dir(), \"proprio_input.pth\")\n",
    "    proprioception_target_path = pathlib.Path(exp.data_dir(), \"proprio_target.pth\")\n",
    "\n",
    "    if proprioception_input_path.exists():\n",
    "        retval[\"inputs\"] = torch.load(proprioception_input_path, weights_only=True)\n",
    "        retval[\"targets\"] = torch.load(proprioception_target_path, weights_only=True)\n",
    "    else:\n",
    "        inputlist = []\n",
    "        targetlist = []\n",
    "        transform = sp_helper.get_transform_to_sp(exp)\n",
    "        for val in exp[\"training_data\"]:\n",
    "            run, demo_name, camera = val\n",
    "            #run = val[0]\n",
    "            #demo_name = val[1]\n",
    "            #camera = val[2]\n",
    "            exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "            demo = Demonstration(exp_demo, demo_name)\n",
    "            for i in range(demo.metadata[\"maxsteps\"]):\n",
    "                sensor_readings, _ = demo.get_image(i, device=device, transform=transform, camera=camera)\n",
    "                inputlist.append(sensor_readings[0])\n",
    "                rp = demo.get_action(i, \"rc-position-target\", exp_robot)\n",
    "                # rp = RobotPosition.from_vector(exp_robot, a)\n",
    "                anorm = rp.to_normalized_vector(exp_robot)\n",
    "                targetlist.append(torch.from_numpy(anorm))\n",
    "        retval[\"inputs\"] = torch.stack(inputlist)\n",
    "        retval[\"targets\"] = torch.stack(targetlist)\n",
    "        torch.save(retval[\"inputs\"], proprioception_input_path)\n",
    "        torch.save(retval[\"targets\"], proprioception_target_path)\n",
    "\n",
    "    # Separate the training and validation data.\n",
    "    # We will be shuffling the demonstrations\n",
    "    length = retval[\"inputs\"].size(0)\n",
    "    rows = torch.randperm(length)\n",
    "    shuffled_inputs = retval[\"inputs\"][rows]\n",
    "    shuffled_targets = retval[\"targets\"][rows]\n",
    "\n",
    "    training_size = int( length * 0.67 )\n",
    "    retval[\"inputs_training\"] = shuffled_inputs[1:training_size]\n",
    "    retval[\"targets_training\"] = shuffled_targets[1:training_size]\n",
    "\n",
    "    retval[\"inputs_validation\"] = shuffled_inputs[training_size:]\n",
    "    retval[\"targets_validation\"] = shuffled_targets[training_size:]\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450cd67",
   "metadata": {
    "papermill": {
     "duration": 0.003267,
     "end_time": "2025-11-18T10:06:51.938081",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.934814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create a model that performs proprioception regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2807fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.945522Z",
     "iopub.status.busy": "2025-11-18T10:06:51.945380Z",
     "iopub.status.idle": "2025-11-18T10:06:51.950630Z",
     "shell.execute_reply": "2025-11-18T10:06:51.949778Z"
    },
    "papermill": {
     "duration": 0.009812,
     "end_time": "2025-11-18T10:06:51.951087",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.941275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_proprioception_model(model, criterion, optimizer, modelfile, train_loader, test_loader, device=\"cpu\", epochs=20):\n",
    "    \"\"\"Trains and saves the proprioception model\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    # Training loop\n",
    "    num_epochs = epochs\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            predictions = model.forward(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    torch.save(model.state_dict(), modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319f9d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:06:51.958762Z",
     "iopub.status.busy": "2025-11-18T10:06:51.958621Z",
     "iopub.status.idle": "2025-11-18T10:06:51.964526Z",
     "shell.execute_reply": "2025-11-18T10:06:51.963616Z"
    },
    "papermill": {
     "duration": 0.010397,
     "end_time": "2025-11-18T10:06:51.964989",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.954592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Train-Propriotuned-CNN ***: NOT training; model already exists\n"
     ]
    }
   ],
   "source": [
    "modelfile = pathlib.Path(\n",
    "    exp[\"data_dir\"], exp[\"proprioception_mlp_model_file\"])\n",
    "\n",
    "if modelfile.exists():\n",
    "    print(\"*** Train-Propriotuned-CNN ***: NOT training; model already exists\")\n",
    "    # model.load_state_dict(torch.load(modelfile))\n",
    "else:\n",
    "    if exp['model'] == 'VGG19ProprioTunedRegression':\n",
    "        model = VGG19ProprioTunedRegression(exp, device)\n",
    "    elif exp['model'] == 'ResNetProprioTunedRegression':\n",
    "        model = ResNetProprioTunedRegression(exp, device)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown model {exp['model']}\")\n",
    "    if exp['loss'] == 'MSELoss':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif exp['loss'] == 'L1Loss':\n",
    "        criterion = nn.L1Loss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=exp['learning_rate'])\n",
    "\n",
    "    tr = load_images_as_proprioception_training(exp, exp_robot)\n",
    "    inputs_training = tr[\"inputs_training\"]\n",
    "    targets_training = tr[\"targets_training\"]\n",
    "    inputs_validation = tr[\"inputs_validation\"]\n",
    "    targets_validation = tr[\"targets_validation\"]\n",
    "\n",
    "    # Create DataLoaders for batching\n",
    "    batch_size = exp['batch_size']\n",
    "    train_dataset = TensorDataset(inputs_training, targets_training)\n",
    "    test_dataset = TensorDataset(inputs_validation, targets_validation)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    if not epochs:\n",
    "        epochs = exp[\"epochs\"]\n",
    "\n",
    "    train_and_save_proprioception_model(model, criterion, optimizer, modelfile, train_loader, test_loader, device=device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a98b77",
   "metadata": {
    "papermill": {
     "duration": 0.003499,
     "end_time": "2025-11-18T10:06:51.973932",
     "exception": false,
     "start_time": "2025-11-18T10:06:51.970433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.062057,
   "end_time": "2025-11-18T10:06:54.621005",
   "environment_variables": {},
   "exception": null,
   "input_path": "../sensorprocessing/Train_ProprioTuned_CNN.ipynb",
   "output_path": "/lustre/fs1/home/sa641631/WORK/BerryPicker/src/BerryPicker/src/visual_proprioception/~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result/Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_resnet50_256_0001_output.ipynb",
   "parameters": {
    "data_path": "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/result",
    "experiment": "sensorprocessing_propriotuned_cnn",
    "external_path": "~/WORK/BerryPicker-Flows/VisualProprioception_flow_01/exprun",
    "run": "sp_resnet50_256_0001"
   },
   "start_time": "2025-11-18T10:06:48.558948",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}