{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bea14d",
   "metadata": {},
   "source": [
    "# Visual proprioception flow\n",
    "\n",
    "Create the full flow for training models for visual proprioception. This notebook programmatically generates a set of exp/runs that cover all the necessary components for a visual proprioception system (sensor processing,  visual proprioception regressor and verification notebooks).\n",
    "\n",
    "Then, it writes the exp/runs into an external directory full separated from the github source, and creates an automation script that runs them. A separate directory for the results is also created. \n",
    "\n",
    "Finally, it runs the necessary notebooks to execute the whole flow using papermill.\n",
    "\n",
    "The results directory contain the output of this flow, both in terms of trained models, as well as results (in the verification exp/run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a83531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import copy\n",
    "import pprint\n",
    "import pathlib\n",
    "import yaml\n",
    "import tqdm\n",
    "import papermill\n",
    "import visproprio_helper \n",
    "from demonstration.demonstration import list_demos\n",
    "from demonstration.demopack import import_demopack, group_chooser_sp_vp_standard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b173f38",
   "metadata": {},
   "source": [
    "# Setting up the separate directory\n",
    "Setting up a separate directory for generated exp/run config files and the results. This cell will create a new directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ac9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lotzi\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tc:\\Users\\lotzi\\Work\\_Config\\BerryPicker\\cfg\\settings.yaml\n",
      "***Path for external experiments:\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\n",
      "***Path for external data:\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\result\n",
      "***ExpRun**: Experiment config path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\n",
      "***ExpRun**: Experiment data path changed to c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\result\n",
      "***ExpRun**: Experiment demonstration copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\demonstration\n",
      "***ExpRun**: Experiment sensorprocessing_conv_vae copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\sensorprocessing_conv_vae\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_cnn copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\sensorprocessing_propriotuned_cnn\n",
      "***ExpRun**: Experiment sensorprocessing_propriotuned_Vit copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\sensorprocessing_propriotuned_Vit\n",
      "***ExpRun**: Experiment sensorprocessing_aruco copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\sensorprocessing_aruco\n",
      "***ExpRun**: Experiment visual_proprioception copied to\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\exprun\\visual_proprioception\n",
      "*** import_demopack: c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Demopacks\\automove-pack-01, target directory c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\result\\demonstration\\automove-pack-01  already exists, not copying\n",
      "***ExpRun**: Configuration for exp/run: demonstration/automove-pack-01 successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# the most likely changing things\n",
    "flow_name = \"VisualProprioception_flow_01\"\n",
    "#demonstration_run = \"touch-apple\"\n",
    "#demopack_name = \"touch-apple\"\n",
    "demopack_name = \"automove-pack-01\"\n",
    "demonstration_cam = \"dev2\"\n",
    "\n",
    "# determine these values based on experience\n",
    "# epochs_sp = 300\n",
    "# epochs_vp = 1000\n",
    "epochs_sp = 300\n",
    "epochs_vp = 1000\n",
    "image_size = [256, 256] # for vgg... etc\n",
    "\n",
    "# Use exist_ok not to-re-run previously successfully run models\n",
    "creation_style = \"exist-ok\"\n",
    "# creation_style = \"discard-old\"\n",
    "\n",
    "exprun_path, result_path = visproprio_helper.external_setup(flow_name, Config()[\"flows_path\"])\n",
    "\n",
    "demopack_path = pathlib.Path(Config()[\"demopacks_path\"], demopack_name)\n",
    "selection = import_demopack(demopack_path, group_chooser_sp_vp_standard)\n",
    "#\n",
    "# Configuring the training and validation data, based \n",
    "# on all the demonstrations of a particular type\n",
    "#\n",
    "experiment = \"demonstration\"\n",
    "exp = Config().get_experiment(experiment, demopack_name)\n",
    "\n",
    "#sp_training_data = selection[\"sp_training\"]\n",
    "#sp_validation_data = selection[\"sp_validation\"]\n",
    "#vp_training_data = selection[\"vp_training\"]\n",
    "#vp_validation_data = selection[\"vp_validation\"]\n",
    "\n",
    "#demos = list_demos(exp)\n",
    "#print(\"***The demos considered\")\n",
    "#pprint.pprint(demos)\n",
    "\n",
    "sp_training_data = []\n",
    "#temp = list_demos(exp, \"sp_training\")\n",
    "# for demo in selection[\"sp_training\"]:\n",
    "#     sp_training_data.append([demopack_name, demo, demonstration_cam])\n",
    "# print(\"***sp_training_data\")\n",
    "# pprint.pprint(sp_training_data)\n",
    "\n",
    "sp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_training\"]]\n",
    "sp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"sp_validation\"]]\n",
    "vp_training_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_training\"]]\n",
    "vp_validation_data = [[demopack_name, demo, demonstration_cam] for demo in selection[\"vp_validation\"]]\n",
    "\n",
    "\n",
    "# sp_validation_data = []\n",
    "# for demo in selection[\"sp_validation\"]:\n",
    "#     sp_validation_data.append([demopack_name, demo, demonstration_cam])\n",
    "\n",
    "# vp_training_data = []\n",
    "# for demo in selection[\"vp_training\"]:\n",
    "#     vp_training_data.append([demopack_name, demo, demonstration_cam])\n",
    "\n",
    "# vp_validation_data = []\n",
    "# for demo in selection[\"vp_validation\"]:\n",
    "#     vp_validation_data.append([demopack_name, demo, demonstration_cam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_training': ['sp_training_00000', 'sp_training_00001', 'sp_training_00002', 'sp_training_00003'], 'sp_validation': ['sp_validation_00000', 'sp_validation_00001'], 'sp_testing': ['sp_testing_00000', 'sp_testing_00001'], 'vp_training': ['vp_training_00000', 'vp_training_00001', 'vp_training_00002', 'vp_training_00003'], 'vp_validation': ['vp_validation_00000', 'vp_validation_00001'], 'vp_testing': ['vp_testing_00000', 'vp_testing_00001']}\n"
     ]
    }
   ],
   "source": [
    "print(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2ada4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sp_testing_00000', 'sp_testing_00001', 'sp_training_00000', 'sp_training_00001', 'sp_training_00002', 'sp_training_00003', 'sp_validation_00000', 'sp_validation_00001']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sp_training_00000',\n",
       " 'sp_training_00001',\n",
       " 'sp_training_00002',\n",
       " 'sp_training_00003']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos = list_demos(exp)\n",
    "# print(demos)\n",
    "print(list_demos(exp, \"sp\"))\n",
    "[s for s in demos if s.startswith(\"sp_training\" + \"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d27c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_conv_vae(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the conv-vae sensorprocessing with the right training data and parameters. Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    NOTE: a similar function is in Flow_BehaviorCloning.\n",
    "    \"\"\"\n",
    "    val = {}\n",
    "    val[\"latent_size\"] = params[\"latent_size\"]\n",
    "    val[\"epochs\"] = params[\"epochs\"]\n",
    "    val[\"save_period\"] = 5\n",
    "    val[\"training_data\"] = params[\"training_data\"]\n",
    "    val[\"validation_data\"] = params[\"validation_data\"]\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_Conv-VAE\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_Conv_VAE.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d97895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sp_propriotuned_cnn(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training of the propriotuned CNN with the right training data and parameters. \n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"output_size\"] = 6\n",
    "    val[\"batch_size\"] = 32\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = \"Train_SP_CNN\"\n",
    "    v[\"notebook\"] = \"sensorprocessing/Train_ProprioTuned_CNN.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476839eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_train(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the training visual proprioception regressor.  \n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    \n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Train_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Train_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99c9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_verify(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.  \n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    \n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Verify_{run_name}\"\n",
    "    v[\"notebook\"] = \"TODO Verify.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64e6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vp_compare(exprun_path, result_path, params, exp_name, run_name):\n",
    "    \"\"\"Generate the experiment for the verification of the visual proprioception regressor.  \n",
    "    Returns a dictionary with the experiment, runname as well as an entry that will be used for the automation. \n",
    "    \"\"\"\n",
    "    val = copy.copy(params)\n",
    "    val[\"name\"] = exp_name\n",
    "\n",
    "    # save the generated exprun spec\n",
    "    path = pathlib.Path(Config().get_exprun_path(), exp_name, run_name + \".yaml\")\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(val, f)\n",
    "    # now, generate the entry in the automation file \n",
    "    v = {}\n",
    "    v[\"name\"] = f\"Compare_{run_name}\"\n",
    "    v[\"notebook\"] = \"visual_proprioception/Compare_VisualProprioception.ipynb\"\n",
    "    v[\"experiment\"] = exp_name\n",
    "    v[\"run\"] = run_name\n",
    "    v[\"external_path\"] = exprun_path.as_posix()\n",
    "    v[\"data_path\"] = result_path.as_posix()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28cd090",
   "metadata": {},
   "source": [
    "### Generate the exp/runs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020b8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorprocessing_conv_vae sp_conv_vae_128_0001 128\n",
      "sensorprocessing_propriotuned_cnn sp_vgg19_128_0001 128\n",
      "sensorprocessing_propriotuned_cnn sp_resnet50_128_0001 128\n",
      "sensorprocessing_conv_vae sp_conv_vae_256_0001 256\n",
      "sensorprocessing_propriotuned_cnn sp_vgg19_256_0001 256\n",
      "sensorprocessing_propriotuned_cnn sp_resnet50_256_0001 256\n"
     ]
    }
   ],
   "source": [
    "expruns = []\n",
    "# overall values\n",
    "latent_sizes = [128, 256] # the possible latent sizes we consider\n",
    "cnntypes = [\"vgg19\", \"resnet50\"] # the CNN architectures we consider\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# *******************************************\n",
    "# generate the sensorprocessing models\n",
    "# *******************************************\n",
    "sps = [] # the list of the sensorprocessing models (exp/run)\n",
    "for latent_size in latent_sizes:\n",
    "\n",
    "    # generate the vae exprun\n",
    "    exp_name = \"sensorprocessing_conv_vae\"\n",
    "    run_name = f\"sp_conv_vae_{latent_size}_0001\"\n",
    "    params = {}\n",
    "    params[\"latent_size\"] = latent_size\n",
    "    params[\"epochs\"] = epochs_sp\n",
    "    params[\"training_data\"] = sp_training_data\n",
    "    params[\"validation_data\"] = sp_validation_data\n",
    "    exprun = generate_sp_conv_vae(\n",
    "        exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "    exprun[\"latent_size\"] = latent_size\n",
    "    sps.append(exprun)\n",
    "    expruns.append(exprun)\n",
    "\n",
    "    # generate the propriotuned expruns\n",
    "    for cnntype in cnntypes:\n",
    "        exp_name = \"sensorprocessing_propriotuned_cnn\"\n",
    "        run_name = f\"sp_{cnntype}_{latent_size}_0001\"\n",
    "        params = {}\n",
    "        params[\"image_size\"] = image_size\n",
    "        params[\"latent_size\"] = latent_size\n",
    "        params[\"epochs\"] = epochs_sp\n",
    "        params[\"training_data\"] = sp_training_data\n",
    "        params[\"validation_data\"] = sp_validation_data\n",
    "        if cnntype == \"vgg19\":\n",
    "            params[\"class\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"VGG19ProprioTunedRegression\"\n",
    "        elif cnntype == \"resnet50\":\n",
    "            params[\"class\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "            params[\"model\"] = \"ResNetProprioTunedRegression\"\n",
    "            params[\"freeze_feature_extractor\"] = True\n",
    "            params[\"reductor_step_1\"] = 512\n",
    "            params[\"proprio_step_1\"] = 64\n",
    "            params[\"proprio_step_2\"] = 16\n",
    "        else:\n",
    "            raise Exception(f\"Unknown cnntype {cnntype}\")\n",
    "        params[\"loss\"] = \"MSELoss\" # alternative L1Loss\n",
    "        params[\"learning_rate\"] = 0.001\n",
    "        # alternative\n",
    "        exprun = generate_sp_propriotuned_cnn(\n",
    "            exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name = run_name)\n",
    "        exprun[\"latent_size\"] = latent_size\n",
    "        exprun[\"cnntype\"] = cnntype\n",
    "        sps.append(exprun)\n",
    "        expruns.append(exprun)\n",
    "\n",
    "    # FIXME: add here the ViT models\n",
    "\n",
    "# *******************************************\n",
    "# generate the proprioception models\n",
    "# *******************************************\n",
    "vpruns = []\n",
    "vpruns_latent = {128:[], 256:[]}\n",
    "for spexp, sprun,latent_size in [(a[\"experiment\"],a[\"run\"],a[\"latent_size\"]) for a in sps]:\n",
    "    print(spexp, sprun, latent_size)\n",
    "    # *** generate the vp train expruns ***\n",
    "    exp_name = \"visual_proprioception\"\n",
    "    run_name = \"vp_\" + sprun[3:]\n",
    "    vpruns.append(run_name)\n",
    "    vpruns_latent[latent_size].append(run_name)\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"output_size\"] = 6\n",
    "    params[\"encoding_size\"] = latent_size\n",
    "    params[\"training_data\"] = vp_training_data\n",
    "    params[\"validation_data\"] = vp_validation_data\n",
    "\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"regressor_hidden_size_1\"] = 64\n",
    "    params[\"loss\"] = \"MSE\"\n",
    "    params[\"epochs\"] = epochs_vp\n",
    "    params[\"batch_size\"] = 64\n",
    "    # FIXME this is hackish, should not do it this way\n",
    "    if \"vae\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ConvVaeSensorProcessing\"\n",
    "    elif \"resnet\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"ResNetProprioTunedSensorProcessing\"\n",
    "    elif \"vgg19\" in sprun.lower():\n",
    "        params[\"sensor_processing\"] = \"VGG19ProprioTunedSensorProcessing\"\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected sprun {sprun}\")\n",
    "\n",
    "    params[\"sp_experiment\"] = spexp\n",
    "    params[\"sp_run\"] = sprun\n",
    "\n",
    "    exprun = generate_vp_train(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    # *** generate the vp verify expruns FIXME: not implemented yet ***\n",
    "    params_verify = {}\n",
    "    \n",
    "    expruns.append(exprun)\n",
    "# *******************************************\n",
    "# generate the comparisons: all, for latents 128 and 256\n",
    "# *******************************************\n",
    "exp_name = \"visual_proprioception\"\n",
    "# all\n",
    "run_name = \"vp_comp_flow_all\"\n",
    "params = {}\n",
    "params[\"name\"] = run_name\n",
    "params[\"tocompare\"] = vpruns\n",
    "exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "expruns.append(exprun)\n",
    "# by latent\n",
    "for latent_size in [128, 256]:\n",
    "    run_name = f\"vp_comp_flow_{latent_size}\"\n",
    "    params = {}\n",
    "    params[\"name\"] = run_name\n",
    "    params[\"tocompare\"] = vpruns_latent[latent_size]\n",
    "    exprun = generate_vp_compare(exprun_path = exprun_path, result_path = result_path, params = params, exp_name = exp_name, run_name=run_name)\n",
    "    expruns.append(exprun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef389ef",
   "metadata": {},
   "source": [
    "### Run the flow\n",
    "\n",
    "Run the flow, that is, run a series of notebooks with papermill. In order to follow the execution inside these notebooks, one needs to open the output notebook, which is in the output_filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21aab023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Starting automated running of the flow.\n",
      " The path for the output notebooks is\n",
      "c:\\Users\\lotzi\\Work\\_Data\\BerryPicker-Flows\\VisualProprioception_flow_01\\result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Automating sensorprocessing/Train_Conv_VAE.ipynb :\n",
      " sensorprocessing_conv_vae/sp_conv_vae_128_0001\n",
      "--> Train_Conv_VAE_sensorprocessing_conv_vae_sp_conv_vae_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e011b003e72543929236cece6875915e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/11 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:03<00:49,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [6]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[6], line 7\n",
      "      5 if not training_image_dir.exists():\n",
      "      6     training_image_dir.mkdir(exist_ok = False, parents=True)\n",
      "----> 7     copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
      "      8 else:\n",
      "      9     print(f\"***Train-Conv-VAE***: Training image dir {training_image_dir} already exists. Do not repeat the copying.\")            \n",
      "\n",
      "Cell In[5], line 7, in copy_images_to_training_dir(exp, training_image_dir)\n",
      "      5 print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
      "      6 for val in exp[\"training_data\"]:\n",
      "----> 7     run, demo_name, camera = val\n",
      "      8     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "      9     demo = Demonstration(exp_demo, demo_name)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_vgg19_128_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_vgg19_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c72e4f36cd485f8636f89a1335bb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:06<00:44,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [7]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[7], line 21\n",
      "     17     criterion = nn.L1Loss()\n",
      "     19 optimizer = optim.Adam(model.parameters(), lr=exp['learning_rate'])\n",
      "---> 21 tr = load_images_as_proprioception_training(exp, exp_robot)\n",
      "     22 inputs_training = tr[\"inputs_training\"]\n",
      "     23 targets_training = tr[\"targets_training\"]\n",
      "\n",
      "Cell In[5], line 19, in load_images_as_proprioception_training(exp, exp_robot)\n",
      "     17 transform = sp_helper.get_transform_to_sp(exp)\n",
      "     18 for val in exp[\"training_data\"]:\n",
      "---> 19     run, demo_name, camera = val\n",
      "     20     #run = val[0]\n",
      "     21     #demo_name = val[1]\n",
      "     22     #camera = val[2]\n",
      "     23     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_resnet50_128_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_resnet50_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3609a70b4bb14dafa6945c68a9d62b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:10<00:39,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [7]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[7], line 21\n",
      "     17     criterion = nn.L1Loss()\n",
      "     19 optimizer = optim.Adam(model.parameters(), lr=exp['learning_rate'])\n",
      "---> 21 tr = load_images_as_proprioception_training(exp, exp_robot)\n",
      "     22 inputs_training = tr[\"inputs_training\"]\n",
      "     23 targets_training = tr[\"targets_training\"]\n",
      "\n",
      "Cell In[5], line 19, in load_images_as_proprioception_training(exp, exp_robot)\n",
      "     17 transform = sp_helper.get_transform_to_sp(exp)\n",
      "     18 for val in exp[\"training_data\"]:\n",
      "---> 19     run, demo_name, camera = val\n",
      "     20     #run = val[0]\n",
      "     21     #demo_name = val[1]\n",
      "     22     #camera = val[2]\n",
      "     23     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating sensorprocessing/Train_Conv_VAE.ipynb :\n",
      " sensorprocessing_conv_vae/sp_conv_vae_256_0001\n",
      "--> Train_Conv_VAE_sensorprocessing_conv_vae_sp_conv_vae_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2b9c6930ad48f5acaa49cfe8c53eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/11 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:13<00:36,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [6]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[6], line 7\n",
      "      5 if not training_image_dir.exists():\n",
      "      6     training_image_dir.mkdir(exist_ok = False, parents=True)\n",
      "----> 7     copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
      "      8 else:\n",
      "      9     print(f\"***Train-Conv-VAE***: Training image dir {training_image_dir} already exists. Do not repeat the copying.\")            \n",
      "\n",
      "Cell In[5], line 7, in copy_images_to_training_dir(exp, training_image_dir)\n",
      "      5 print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
      "      6 for val in exp[\"training_data\"]:\n",
      "----> 7     run, demo_name, camera = val\n",
      "      8     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "      9     demo = Demonstration(exp_demo, demo_name)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_vgg19_256_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_vgg19_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9042f4bd8627455aadc5d6791eec5479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:16<00:33,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [7]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[7], line 21\n",
      "     17     criterion = nn.L1Loss()\n",
      "     19 optimizer = optim.Adam(model.parameters(), lr=exp['learning_rate'])\n",
      "---> 21 tr = load_images_as_proprioception_training(exp, exp_robot)\n",
      "     22 inputs_training = tr[\"inputs_training\"]\n",
      "     23 targets_training = tr[\"targets_training\"]\n",
      "\n",
      "Cell In[5], line 19, in load_images_as_proprioception_training(exp, exp_robot)\n",
      "     17 transform = sp_helper.get_transform_to_sp(exp)\n",
      "     18 for val in exp[\"training_data\"]:\n",
      "---> 19     run, demo_name, camera = val\n",
      "     20     #run = val[0]\n",
      "     21     #demo_name = val[1]\n",
      "     22     #camera = val[2]\n",
      "     23     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating sensorprocessing/Train_ProprioTuned_CNN.ipynb :\n",
      " sensorprocessing_propriotuned_cnn/sp_resnet50_256_0001\n",
      "--> Train_ProprioTuned_CNN_sensorprocessing_propriotuned_cnn_sp_resnet50_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781e08197a1e43c68c9f217059244cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:19<00:29,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [7]\":\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "Cell In[7], line 21\n",
      "     17     criterion = nn.L1Loss()\n",
      "     19 optimizer = optim.Adam(model.parameters(), lr=exp['learning_rate'])\n",
      "---> 21 tr = load_images_as_proprioception_training(exp, exp_robot)\n",
      "     22 inputs_training = tr[\"inputs_training\"]\n",
      "     23 targets_training = tr[\"targets_training\"]\n",
      "\n",
      "Cell In[5], line 19, in load_images_as_proprioception_training(exp, exp_robot)\n",
      "     17 transform = sp_helper.get_transform_to_sp(exp)\n",
      "     18 for val in exp[\"training_data\"]:\n",
      "---> 19     run, demo_name, camera = val\n",
      "     20     #run = val[0]\n",
      "     21     #demo_name = val[1]\n",
      "     22     #camera = val[2]\n",
      "     23     exp_demo = Config().get_experiment(\"demonstration\", run)\n",
      "\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_conv_vae_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_conv_vae_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ed05dc2e40440ebedd88c0021fd6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:23<00:26,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\_local.py:537, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "    535 if \"b\" not in mode:\n",
      "    536     encoding = io.text_encoding(encoding)\n",
      "--> 537 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\VisualProprioception_flow_01\\\\result\\\\sensorprocessing_conv_vae\\\\sp_conv_vae_128_0001\\\\config.json'\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_vgg19_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_vgg19_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde7b2d2b15e47bcb2c6973f034df4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:27<00:24,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:20, in create_sp(spexp, device)\n",
      "     18     return sp_conv_vae_multiview.ConvVaeSensorProcessing_multiview(spexp, device)\n",
      "     19 if spexp['class']==\"VGG19ProprioTunedSensorProcessing\":\n",
      "---> 20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "     22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_propriotuned_cnn.py:170, in VGG19ProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    167 self.enc = self.enc.to(device)\n",
      "    168 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    169                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 170 assert modelfile.exists()\n",
      "    171 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_resnet50_128_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_resnet50_128_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8741f64d288494fb2025776fb5e6bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:30<00:21,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:22, in create_sp(spexp, device)\n",
      "     20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "---> 22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "     23 if spexp['class']==\"VGG19ProprioTunedSensorProcessing_multiview\":\n",
      "     24     return sp_propriotuned_cnn_multiview.MultiViewVGG19SensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_propriotuned_cnn.py:148, in ResNetProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    145 self.enc = ResNetProprioTunedRegression(exp, device)\n",
      "    146 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    147                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 148 assert modelfile.exists()\n",
      "    149 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_conv_vae_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_conv_vae_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf15d670a174338be11444ac71d9cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:34<00:17,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\_local.py:537, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "    535 if \"b\" not in mode:\n",
      "    536     encoding = io.text_encoding(encoding)\n",
      "--> 537 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\VisualProprioception_flow_01\\\\result\\\\sensorprocessing_conv_vae\\\\sp_conv_vae_256_0001\\\\config.json'\n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_vgg19_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_vgg19_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655a073b7f60454988e9a9db8d129a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:38<00:14,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:20, in create_sp(spexp, device)\n",
      "     18     return sp_conv_vae_multiview.ConvVaeSensorProcessing_multiview(spexp, device)\n",
      "     19 if spexp['class']==\"VGG19ProprioTunedSensorProcessing\":\n",
      "---> 20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "     22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_propriotuned_cnn.py:170, in VGG19ProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    167 self.enc = self.enc.to(device)\n",
      "    168 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    169                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 170 assert modelfile.exists()\n",
      "    171 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Train_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_resnet50_256_0001\n",
      "--> Train_VisualProprioception_visual_proprioception_vp_resnet50_256_0001_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb48c65dac246f3bc9b1b735692c4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:42<00:11,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "AssertionError                            Traceback (most recent call last)\n",
      "Cell In[4], line 22\n",
      "     20 # Create the sp object described in the experiment\n",
      "     21 spexp = Config().get_experiment(exp[\"sp_experiment\"], exp[\"sp_run\"])\n",
      "---> 22 sp = create_sp(spexp, device)\n",
      "     23 exp_robot = Config().get_experiment(exp[\"robot_exp\"], exp[\"robot_run\"])\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:22, in create_sp(spexp, device)\n",
      "     20     return sp_propriotuned_cnn.VGG19ProprioTunedSensorProcessing(spexp, device)\n",
      "     21 if spexp['class']==\"ResNetProprioTunedSensorProcessing\":\n",
      "---> 22     return sp_propriotuned_cnn.ResNetProprioTunedSensorProcessing(spexp, device)\n",
      "     23 if spexp['class']==\"VGG19ProprioTunedSensorProcessing_multiview\":\n",
      "     24     return sp_propriotuned_cnn_multiview.MultiViewVGG19SensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_propriotuned_cnn.py:148, in ResNetProprioTunedSensorProcessing.__init__(self, exp, device)\n",
      "    145 self.enc = ResNetProprioTunedRegression(exp, device)\n",
      "    146 modelfile = pathlib.Path(exp[\"data_dir\"], \n",
      "    147                         exp[\"proprioception_mlp_model_file\"])\n",
      "--> 148 assert modelfile.exists()\n",
      "    149 self.enc.load_state_dict(torch.load(modelfile))\n",
      "\n",
      "AssertionError: \n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_all\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_all_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f9b21c854e47628b61fd7a74ed3041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/18 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:45<00:07,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[4], line 38\n",
      "     36 spexp = Config().get_experiment(subexp[\"sp_experiment\"], subexp[\"sp_run\"])\n",
      "     37 spexps.append(spexp)\n",
      "---> 38 sp = sp_factory.create_sp(spexp, device)\n",
      "     39 sps.append(sp)\n",
      "     40 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\_local.py:537, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "    535 if \"b\" not in mode:\n",
      "    536     encoding = io.text_encoding(encoding)\n",
      "--> 537 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\VisualProprioception_flow_01\\\\result\\\\sensorprocessing_conv_vae\\\\sp_conv_vae_128_0001\\\\config.json'\n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_128\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_128_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34425911a6cf448c86a771d1b240f3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/18 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:48<00:03,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[4], line 38\n",
      "     36 spexp = Config().get_experiment(subexp[\"sp_experiment\"], subexp[\"sp_run\"])\n",
      "     37 spexps.append(spexp)\n",
      "---> 38 sp = sp_factory.create_sp(spexp, device)\n",
      "     39 sps.append(sp)\n",
      "     40 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\_local.py:537, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "    535 if \"b\" not in mode:\n",
      "    536     encoding = io.text_encoding(encoding)\n",
      "--> 537 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\VisualProprioception_flow_01\\\\result\\\\sensorprocessing_conv_vae\\\\sp_conv_vae_128_0001\\\\config.json'\n",
      "\n",
      "***Automating visual_proprioception/Compare_VisualProprioception.ipynb :\n",
      " visual_proprioception/vp_comp_flow_256\n",
      "--> Compare_VisualProprioception_visual_proprioception_vp_comp_flow_256_output.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc98296562db48989fa60841355afa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/18 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:52<00:00,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an exception \n",
      "---------------------------------------------------------------------------\n",
      "Exception encountered at \"In [4]\":\n",
      "---------------------------------------------------------------------------\n",
      "FileNotFoundError                         Traceback (most recent call last)\n",
      "Cell In[4], line 38\n",
      "     36 spexp = Config().get_experiment(subexp[\"sp_experiment\"], subexp[\"sp_run\"])\n",
      "     37 spexps.append(spexp)\n",
      "---> 38 sp = sp_factory.create_sp(spexp, device)\n",
      "     39 sps.append(sp)\n",
      "     40 model = VisProprio_SimpleMLPRegression(subexp)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_factory.py:14, in create_sp(spexp, device)\n",
      "     12 # spexp = Config().get_experiment(exp['sp_experiment'], exp['sp_run'])\n",
      "     13 if spexp[\"class\"] == \"ConvVaeSensorProcessing\":\n",
      "---> 14     return sp_conv_vae.ConvVaeSensorProcessing(spexp, device)\n",
      "     15 if spexp[\"class\"] == \"ConvVaeSensorProcessing_concat_multiview\":\n",
      "     16     return sp_conv_vae_concat_multiview.ConcatConvVaeSensorProcessing(spexp, device)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\sp_conv_vae.py:63, in ConvVaeSensorProcessing.__init__(self, exp, device)\n",
      "     60 self.resume_model_pthfile = Path(exp.data_dir(), \"model.pth\")\n",
      "     61 # self.conv_vae_jsonfile = conv_vae_jsonfile\n",
      "     62 # self.resume_model_pthfile = resume_model_pthfile\n",
      "---> 63 self.vae_config = get_conv_vae_config(\n",
      "     64     self.conv_vae_jsonfile, \n",
      "     65     self.resume_model_pthfile, \n",
      "     66     inference_only=True)\n",
      "     67 # build model architecture\n",
      "     68 self.model = self.vae_config.init_obj('arch', module_arch)\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\BerryPicker\\src\\visual_proprioception\\..\\sensorprocessing\\conv_vae.py:217, in get_conv_vae_config(jsonfile, resume_model, inference_only)\n",
      "    215 savedargv = sys.argv\n",
      "    216 sys.argv = value\n",
      "--> 217 config = ConfigParser.from_args(args)\n",
      "    218 sys.argv = savedargv\n",
      "    219 # print(json.dumps(config.config, indent=4))\n",
      "    220 #\n",
      "    221 # THIS was an attempt to fix some kind of weird bug where an empty \n",
      "    222 # directory was created... it is not needed on 2024.11.17???\n",
      "    223 # if it is inference only, remove the superfluously created directories.\n",
      "    224 #\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\parse_config.py:71, in ConfigParser.from_args(cls, args, options)\n",
      "     68     resume = None\n",
      "     69     cfg_fname = Path(args.config)\n",
      "---> 71 config = read_json(cfg_fname)\n",
      "     72 if args.config and resume:\n",
      "     73     # update new config for fine-tuning\n",
      "     74     config.update(read_json(args.config))\n",
      "\n",
      "File c:\\Users\\lotzi\\Work\\_Code\\Conv-VAE-PyTorch\\utils\\util.py:16, in read_json(fname)\n",
      "     14 def read_json(fname):\n",
      "     15     fname = Path(fname)\n",
      "---> 16     with fname.open('rt') as handle:\n",
      "     17         return json.load(handle, object_hook=OrderedDict)\n",
      "\n",
      "File C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib\\_local.py:537, in Path.open(self, mode, buffering, encoding, errors, newline)\n",
      "    535 if \"b\" not in mode:\n",
      "    536     encoding = io.text_encoding(encoding)\n",
      "--> 537 return io.open(self, mode, buffering, encoding, errors, newline)\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lotzi\\\\Work\\\\_Data\\\\BerryPicker-Flows\\\\VisualProprioception_flow_01\\\\result\\\\sensorprocessing_conv_vae\\\\sp_conv_vae_256_0001\\\\config.json'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"***Starting automated running of the flow.\\n The path for the output notebooks is\\n{result_path}\")\n",
    "\n",
    "for exprun in tqdm.tqdm(expruns):\n",
    "    print(f\"***Automating {exprun['notebook']} :\\n {exprun['experiment']}/{exprun['run']}\")\n",
    "    notebook_path = pathlib.Path(\"..\", exprun[\"notebook\"])\n",
    "    output_filename = f\"{notebook_path.stem}_{exprun['experiment']}_{exprun['run']}_output{notebook_path.suffix}\"\n",
    "    print(f\"--> {output_filename}\")\n",
    "    # parameters that we are passing on to the notebook\n",
    "    params = {}\n",
    "    params[\"experiment\"] = exprun[\"experiment\"]\n",
    "    params[\"run\"] = exprun[\"run\"]\n",
    "    params[\"external_path\"] = exprun[\"external_path\"]\n",
    "    params[\"data_path\"] = exprun[\"data_path\"]    \n",
    "    output_path = pathlib.Path(result_path, output_filename)\n",
    "    try:\n",
    "        papermill.execute_notebook(\n",
    "            notebook_path,\n",
    "            output_path.absolute(),\n",
    "            cwd=notebook_path.parent,\n",
    "            parameters=params\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"There was an exception {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8455f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
