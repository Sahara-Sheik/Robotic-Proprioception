{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: Loading pointer config file:\n",
      "\tC:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "***ExpRun**: Loading machine-specific config file:\n",
      "\tG:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import pprint\n",
    "from demonstration.demonstration import Demonstration, get_simple_transform\n",
    "\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "sys.path.append(Config()[\"conv_vae\"][\"code_dir\"])\n",
    "\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\sensorprocessing_conv_vae\\sp_vae_128_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: sensorprocessing_conv_vae/sp_vae_128 successfully loaded\n",
      "Experiment:\n",
      "    class: ConvVaeSensorProcessing\n",
      "    data_dir: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_128\n",
      "    epochs: 100\n",
      "    exp_run_sys_indep_file: C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\sensorprocessing_conv_vae\\sp_vae_128.yaml\n",
      "    experiment_name: sensorprocessing_conv_vae\n",
      "    image_size:\n",
      "    - 64\n",
      "    - 64\n",
      "    json_template_name: conv-vae-config-default.json\n",
      "    latent_size: 128\n",
      "    model_dir: models\n",
      "    model_name: VAE_Robot\n",
      "    run_name: sp_vae_128\n",
      "    save_period: 5\n",
      "    subrun_name: null\n",
      "    time_started: '2025-06-14 19:54:34.468469'\n",
      "    training_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_15_53'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_16_57'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_19_12'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_21_28'\n",
      "      - dev2\n",
      "    training_data_dir: vae-training-data\n",
      "    validation_data:\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_23_19'\n",
      "      - dev2\n",
      "    - - random-both-cameras\n",
      "      - '2025_03_08__14_24_52'\n",
      "      - dev2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If it is set to true, no actual copying will be done\n",
    "dry_run = False\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "run = \"sp_vae_128\" \n",
    "# run = \"sp_vae_128_300epochs\" \n",
    "# run = \"sp_vae_256\" \n",
    "# run = \"sp_vae_256_300epochs\" \n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint.pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_training_dir(exp, training_image_dir):\n",
    "    \"\"\"Copy all the images specified in the training_data field to the training directory.\"\"\"\n",
    "    count = 0\n",
    "    transform = get_simple_transform()\n",
    "    print(\"***Train-Conv-VAE***: Copying training images to training directory\")\n",
    "    for val in exp[\"training_data\"]:\n",
    "        run, demo_name, camera = val\n",
    "        exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "        demo = Demonstration(exp_demo, demo_name)\n",
    "        for i in range(demo.metadata[\"maxsteps\"]):\n",
    "            training_image_path = pathlib.Path(training_image_dir, f\"train_{count:05d}.jpg\")\n",
    "            demo.write_image(i, training_image_path, camera=camera, transform=transform)\n",
    "            count += 1\n",
    "    print(f\"***Train-Conv-VAE***: Copying training images to training directory done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: Copying training images to training directory\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_defaults_demonstration.yaml was empty, ok.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\random-both-cameras_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_defaults_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\random-both-cameras_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_defaults_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\random-both-cameras_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras successfully loaded\n",
      "***ExpRun**: Experiment default config C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\demonstration\\_defaults_demonstration.yaml was empty, ok.\n",
      "***ExpRun**: No system dependent experiment file\n",
      "\t G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\demonstration\\random-both-cameras_sysdep.yaml,\n",
      "\t that is ok, proceeding.\n",
      "***ExpRun**: Configuration for exp/run: demonstration/random-both-cameras successfully loaded\n",
      "***Train-Conv-VAE***: Copying training images to training directory done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp.data_dir(), exp[\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "# We assume that if the directory, exists, it had been previously populated with images\n",
    "if not training_image_dir.exists():\n",
    "    training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "    copy_images_to_training_dir(exp, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(\"***Train-Conv-VAE***: There are already images in training image dir {training_image_dir}. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\sensorprocessing\\conv-vae-config-default.json\n",
      "{'name': 'VAE_Robot', 'n_gpu': 1, 'arch': {'type': 'VanillaVAE', 'args': {'in_channels': 3, 'latent_dims': 128, 'flow': False}}, 'data_loader': {'type': 'CelebDataLoader', 'args': {'data_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\sp_vae_128\\\\vae-training-data', 'batch_size': 64, 'shuffle': True, 'validation_split': 0.2, 'num_workers': 2}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.005, 'weight_decay': 0.0, 'amsgrad': True}}, 'loss': 'elbo_loss', 'metrics': [], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 100, 'save_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\sensorprocessing_conv_vae\\\\sp_vae_128\\\\models', 'save_period': 5, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 10, 'tensorboard': True}}\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_128\\models\\conv-vae-configured.json\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n",
      "***Train-Conv-VAE***: Running the trainer from scratch for 100 epochs\n",
      "***Timer*** training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "DEBUG:trainer:Train Epoch: 1 [0/1403 (0%)] Loss: 294933.500000\n",
      "DEBUG:trainer:Train Epoch: 1 [512/1403 (36%)] Loss: 53231.511719\n",
      "DEBUG:trainer:Train Epoch: 1 [1024/1403 (73%)] Loss: 49202.496094\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    loss           : 75117.29971590909\n",
      "WARNING:trainer:Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "DEBUG:trainer:Train Epoch: 2 [0/1403 (0%)] Loss: 46753.941406\n",
      "DEBUG:trainer:Train Epoch: 2 [512/1403 (36%)] Loss: 37318.527344\n",
      "DEBUG:trainer:Train Epoch: 2 [1024/1403 (73%)] Loss: 37989.683594\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    loss           : 43255.24875710227\n",
      "DEBUG:trainer:Train Epoch: 3 [0/1403 (0%)] Loss: 57959.183594\n",
      "DEBUG:trainer:Train Epoch: 3 [512/1403 (36%)] Loss: 102531.140625\n",
      "DEBUG:trainer:Train Epoch: 3 [1024/1403 (73%)] Loss: 39662.707031\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    loss           : 59150.25887784091\n",
      "DEBUG:trainer:Train Epoch: 4 [0/1403 (0%)] Loss: 33561.187500\n",
      "DEBUG:trainer:Train Epoch: 4 [512/1403 (36%)] Loss: 29950.253906\n",
      "DEBUG:trainer:Train Epoch: 4 [1024/1403 (73%)] Loss: 27968.968750\n",
      "INFO:trainer:    epoch          : 4\n",
      "INFO:trainer:    loss           : 29318.09845525568\n",
      "DEBUG:trainer:Train Epoch: 5 [0/1403 (0%)] Loss: 26100.433594\n",
      "DEBUG:trainer:Train Epoch: 5 [512/1403 (36%)] Loss: 24321.185547\n",
      "DEBUG:trainer:Train Epoch: 5 [1024/1403 (73%)] Loss: 22630.982422\n",
      "INFO:trainer:    epoch          : 5\n",
      "INFO:trainer:    loss           : 23529.774680397728\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_128\\models\\models\\VAE_Robot\\0614_195503\\checkpoint-epoch5.pth ...\n",
      "DEBUG:trainer:Train Epoch: 6 [0/1403 (0%)] Loss: 20671.679688\n",
      "DEBUG:trainer:Train Epoch: 6 [512/1403 (36%)] Loss: 17736.419922\n",
      "DEBUG:trainer:Train Epoch: 6 [1024/1403 (73%)] Loss: 16203.380859\n",
      "INFO:trainer:    epoch          : 6\n",
      "INFO:trainer:    loss           : 16681.035422585228\n",
      "DEBUG:trainer:Train Epoch: 7 [0/1403 (0%)] Loss: 12882.776367\n",
      "DEBUG:trainer:Train Epoch: 7 [512/1403 (36%)] Loss: 13203.838867\n",
      "DEBUG:trainer:Train Epoch: 7 [1024/1403 (73%)] Loss: 12545.353516\n",
      "INFO:trainer:    epoch          : 7\n",
      "INFO:trainer:    loss           : 13231.410511363636\n",
      "DEBUG:trainer:Train Epoch: 8 [0/1403 (0%)] Loss: 11802.973633\n",
      "DEBUG:trainer:Train Epoch: 8 [512/1403 (36%)] Loss: 11558.145508\n",
      "DEBUG:trainer:Train Epoch: 8 [1024/1403 (73%)] Loss: 11104.138672\n",
      "INFO:trainer:    epoch          : 8\n",
      "INFO:trainer:    loss           : 11706.470037286932\n",
      "DEBUG:trainer:Train Epoch: 9 [0/1403 (0%)] Loss: 10894.076172\n",
      "DEBUG:trainer:Train Epoch: 9 [512/1403 (36%)] Loss: 10744.728516\n",
      "DEBUG:trainer:Train Epoch: 9 [1024/1403 (73%)] Loss: 12262.162109\n",
      "INFO:trainer:    epoch          : 9\n",
      "INFO:trainer:    loss           : 11564.065873579546\n",
      "DEBUG:trainer:Train Epoch: 10 [0/1403 (0%)] Loss: 11160.340820\n",
      "DEBUG:trainer:Train Epoch: 10 [512/1403 (36%)] Loss: 11064.603516\n",
      "DEBUG:trainer:Train Epoch: 10 [1024/1403 (73%)] Loss: 11298.536133\n",
      "INFO:trainer:    epoch          : 10\n",
      "INFO:trainer:    loss           : 11331.757368607954\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_128\\models\\models\\VAE_Robot\\0614_195503\\checkpoint-epoch10.pth ...\n",
      "DEBUG:trainer:Train Epoch: 11 [0/1403 (0%)] Loss: 11739.161133\n",
      "DEBUG:trainer:Train Epoch: 11 [512/1403 (36%)] Loss: 10811.016602\n",
      "DEBUG:trainer:Train Epoch: 11 [1024/1403 (73%)] Loss: 11033.203125\n",
      "INFO:trainer:    epoch          : 11\n",
      "INFO:trainer:    loss           : 11165.872602982954\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***Train-Conv-VAE***: Running the trainer from scratch for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvae_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m exp\u001b[38;5;241m.\u001b[39mstart_timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m exp\u001b[38;5;241m.\u001b[39mend_timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\sensorprocessing\\conv_vae.py:106\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     97\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler, optimizer)\n\u001b[0;32m    100\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, criterion, optimizer,\n\u001b[0;32m    101\u001b[0m                   config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    102\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    103\u001b[0m                   data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m    104\u001b[0m                   valid_data_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m                   lr_scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler)\n\u001b[1;32m--> 106\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# return the trainer, as the metrics might be useful\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\base\\base_trainer.py:66\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m not_improved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# save logged informations into log dict\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\trainer\\trainer.py:50\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[0;32m     51\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the vae configuration, based on the experiment\n",
    "file = create_configured_vae_json(exp)\n",
    "print(file)\n",
    "vae_config = get_conv_vae_config(file)\n",
    "\n",
    "# actually run the training\n",
    "print(f'***Train-Conv-VAE***: Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]} epochs')\n",
    "exp.start_timer(\"training\")\n",
    "trainer = train(vae_config)\n",
    "exp.end_timer(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.util.MetricTracker object at 0x000001C255F32210>\n",
      "<utils.util.MetricTracker object at 0x000001C256A80910>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>counts</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>83737.937744</td>\n",
       "      <td>22</td>\n",
       "      <td>3806.269897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total counts      average\n",
       "loss  83737.937744     22  3806.269897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metrics recorded\n",
    "# they are of utils/util.py / MetricTracker which has a pandas dataframe as data\n",
    "print(trainer.train_metrics)\n",
    "print(trainer.valid_metrics)\n",
    "# \n",
    "trainer.train_metrics._data\n",
    "# trainer.valid_metrics._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important__ After the training finished, in order to use the resulting system, one need to edit the run file (eg: vae_01.yaml) and enter into it the location of the checkpoint. This is the content printed by the code cell below\n",
    "\n",
    "__Important__ Right now, it is set up such that only every 5. epoch is checkmarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_subdir: '0529_200430'\n",
      "model_checkpoint: 'checkpoint-epoch300.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"model_subdir: '{trainer.checkpoint_dir.name}'\")\n",
    "print(f\"model_checkpoint: 'checkpoint-epoch{trainer.epochs}.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the system dependent experiment run file does not exist,\n",
      " the text can be put into the system independent file\n",
      " C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\experiment_configs\\sensorprocessing_conv_vae\\sp_vae_256_300epochs.yaml\n"
     ]
    }
   ],
   "source": [
    "if \"exp_run_sys_dep_file\" in exp:\n",
    "    print(f'The text above to be put into \\n the system dependent experiment run file {exp[\"exp_run_sys_dep_file\"]}')\n",
    "else:\n",
    "    print(f'As the system dependent experiment run file does not exist,\\n the text can be put into the system independent file\\n {exp[\"exp_run_sys_indep_file\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Train-Conv-VAE***: Copying the checkpoint from c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_256_300epochs\\models\\models\\VAE_Robot\\0529_200430\\checkpoint-epoch300.pth to c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_256_300epochs\\model.pth\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = pathlib.Path(trainer.checkpoint_dir, f\"checkpoint-epoch{trainer.epochs}.pth\")\n",
    "model_target_path = pathlib.Path(exp.data_dir(), \"model.pth\")\n",
    "\n",
    "json_path = pathlib.Path(trainer.checkpoint_dir, \"config.json\")\n",
    "json_target_path = pathlib.Path(exp.data_dir(), \"config.json\")\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"***Train-Conv-VAE***: Copying the checkpoint from {checkpoint_path} to {model_target_path}\")\n",
    "    model_target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(checkpoint_path, model_target_path)\n",
    "    # target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(json_path, json_target_path)\n",
    "else:\n",
    "    print(f\"***Train-Conv-VAE***: The checkpoint file {checkpoint_path} does not exist. Cannot copy it to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_256_300epochs\\models\\models\\VAE_Robot\\0529_200430\n",
      "True\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\sensorprocessing_conv_vae\\sp_vae_256_300epochs\\models\\models\\VAE_Robot\\0529_200430\\checkpoint-epoch300.pth\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(trainer.checkpoint_dir)\n",
    "print(trainer.checkpoint_dir.exists())\n",
    "print(checkpoint_path)\n",
    "print(checkpoint_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
