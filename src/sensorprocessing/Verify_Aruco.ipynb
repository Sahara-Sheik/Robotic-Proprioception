{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Aruco sensorprocessing\n",
    "\n",
    "This notebook verifies that the Aruco sensorprocessing detects the markers in the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from exp_run_config import Config\n",
    "Config.PROJECTNAME = \"BerryPicker\"\n",
    "\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from demonstration.demonstration import Demonstration\n",
    "\n",
    "from sensorprocessing.sp_helper import get_transform_to_sp\n",
    "from sensorprocessing import sp_aruco\n",
    "import random\n",
    "import torch\n",
    "# Move data to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the experiment\n",
    "experiment = \"sensorprocessing_aruco\"\n",
    "run = \"aruco_128\" \n",
    "exp = Config().get_experiment(experiment, run, creation_style=\"discard-old\")\n",
    "pprint.pprint(exp)\n",
    "sp = sp_aruco.ArucoSensorProcessing(exp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform_to_sp(exp)\n",
    "demos = []\n",
    "cameras = []\n",
    "# load the demonstrations specified in the experiment validation data\n",
    "for val in exp[\"validation_data\"]:\n",
    "    run, demo_name, camera = val\n",
    "    exp_demo = Config().get_experiment(\"demonstration\", run)\n",
    "    demo = Demonstration(exp_demo, demo_name)\n",
    "    demos.append(demo)\n",
    "    cameras.append(camera)\n",
    "\n",
    "# Choose n pictures from the validation set and store them in lists of images and imagefiles\n",
    "n = 6\n",
    "demo = demos[0]\n",
    "camera = cameras[0]\n",
    "images = []\n",
    "imagefiles = []\n",
    "for i in range(demo.metadata[\"maxsteps\"]):\n",
    "    rnd = random.randint(0, demo.metadata[\"maxsteps\"] - 1)\n",
    "    imagefiles.append(demo.get_image_path(rnd))\n",
    "    image, _ = demo.get_image(rnd, device=device, camera=camera, transform=transform)\n",
    "    images.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify whether we can process the images loaded from the demonstration\n",
    "for image in images:\n",
    "    z = sp.process(image)\n",
    "    print(f\"The encoding is\\n {z}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
